# Nacos架构总结

## 架构图 

整体架构分为用户层、业务层、内核层和插件。

- **用户层：**解决用户使用的易用性问题 
- **业务层：**解决服务发现和配置管理的功能问题
- **内核层：**解决分布式系统⼀致性、存储、高可用等核心问题
- **插件：**解决扩展性问题

![image-20220613122309498](https://tva1.sinaimg.cn/large/e6c9d24ely1h36i1goel2j20zy0pqq7r.jpg)

**用户层：**

- OpenAPI：暴露标准 Rest 风格 HTTP 接口，简单易用，方便多语言集成
- Console：易用控制台，做服务管理、配置管理等操作
- SDK：多语言 SDK，目前几乎支持所有主流编程语言
-  Agent：Sidecar 模式运行，通过标准 DNS 协议与业务解耦
- CLI：命令行对产品进行轻量化管理，像 git 

**业务层：**

- 服务管理：实现服务 CRUD，域名 CRUD，服务健康状态检查，服务权重管理等功能
- 配置管理：实现配置管 CRUD，版本管理，灰度管理，监听管理，推送轨迹，聚合数据等功能
- 元数据管理：提供元数据 CURD 和打标能力，为实现上层流量和服务灰度非常关键

**为什么 Nacos 需要⼀致性协议？**

集群模式下，需要考虑如何保障各个节点之间的数据⼀致性以及数据同步，而要解决这个问题，就不得不引入共识算法，通过算法来保障各个节点之间的数据的⼀致性。

**为什么 Nacos 选择了 Raft 以及 Distro？**

Nacos 会在单个集群中同时运行 CP 协议以及 AP 协议呢？

Nacos 是⼀个集服务注册发现以及配置管理于⼀体的组件，因此对于集群下，各个节点之间 

的数据⼀致性保障问题，需要拆分成两个方面



**从服务注册发现来看**

服务发现注册中心，在当前微服务体系下，是十分重要的组件。在任何场景下，尽最大可能保证服务注册发现能力可以对外提供服务；同时 Nacos 的服务注册发现设计，采取了心跳可自动完成服务数据补偿的机制。如果数据丢失的话，是可以通过该机制快速弥补数据丢失。

因此，为了满足服务发现注册中心的可用性，强⼀致性的共识算法这里就不太合适了，因为强⼀致性共识算法能否对外提供服务是有要求的，如果当前集群可用的节点数没有过半的话，整个算法直接“罢工”，而最终⼀致共识算法的话，更多保障服务的可用性，并且能够保证在⼀定的时间内各个节点之间的数据能够达成⼀致。

**从配置管理来看**

发布重要配置变更出现了丢失变更动作的情况，那多半就要引起严重的现网故障了，因此对于配置数据的管理，是必须要求集群中大部分的节点是强⼀致的，而这里的话只能使用强⼀致性共识算法。 

**为什么是 Raft 和 Distro 呢？**

并且有很多成熟的工业算法实现，比如蚂蚁金服的 JRaft、Zookeeper 的 ZAB、Consul 的 Raft、 

百度的 braft、Apache Ratis；因为 Nacos 是 Java 技术栈，因此只能在 JRaft、ZAB、ApacheRatis 中选择，但是 ZAB 因为和 Zookeeper 强绑定，再加上希望可以和 Raft 算法库的支持团队随时沟通交流，因此选择了 JRaft，选择 JRaft 也是因为 JRaft 支持多 RaftGroup，为 Nacos 后面的多数据分片带来了可能。而 Distro 协议是阿里巴巴自研的⼀个最终⼀致性协议，而最终⼀致性协议有很多，比如 Gossip、Eureka 内的数据同步算法。



而 Distro 算法是集 Gossip 以及 Eureka 协议的优点并加以优化而出来的，对于原生的 Gossip，由于随机选取发送消息的节点，也就不可避免的存在消息重复发送给同⼀节点的情况，增加了网络的传输的压力，也给消息节点带来额外的处理负载，而 Distro 算法引入了权威 Server 的概念，每个节点负责⼀部分数据以及将自己的数据同步给其他节点，有效的降低了消息冗余的问题。